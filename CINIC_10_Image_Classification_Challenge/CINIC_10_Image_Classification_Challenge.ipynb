{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CINIC-10 Image Classification Challenge.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLx_wU5KzJcd",
        "outputId": "65a5ced6-14a9-4aec-ea74-2d729a69d578"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZMRZolAzKkg",
        "outputId": "c1b33554-cbc6-4e64-c321-7cae2a7227ff"
      },
      "source": [
        "!wget -O \"cinic-10_image_classification_challenge-dataset.zip\" \"https://dockship-job-models.s3.ap-south-1.amazonaws.com/0509b6a7a4588a3267671539207f027c?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIDOPTEUZ2LEOQEGQ%2F20210417%2Fap-south-1%2Fs3%2Faws4_request&X-Amz-Date=20210417T074807Z&X-Amz-Expires=1800&X-Amz-Signature=69b05007b50acae630920eda7c154eed3208e2849c30eb7c3b4379319e1fcffd&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3D%22cinic-10_image_classification_challenge-dataset.zip%22\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-17 07:48:18--  https://dockship-job-models.s3.ap-south-1.amazonaws.com/0509b6a7a4588a3267671539207f027c?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIDOPTEUZ2LEOQEGQ%2F20210417%2Fap-south-1%2Fs3%2Faws4_request&X-Amz-Date=20210417T074807Z&X-Amz-Expires=1800&X-Amz-Signature=69b05007b50acae630920eda7c154eed3208e2849c30eb7c3b4379319e1fcffd&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3D%22cinic-10_image_classification_challenge-dataset.zip%22\n",
            "Resolving dockship-job-models.s3.ap-south-1.amazonaws.com (dockship-job-models.s3.ap-south-1.amazonaws.com)... 52.219.62.95\n",
            "Connecting to dockship-job-models.s3.ap-south-1.amazonaws.com (dockship-job-models.s3.ap-south-1.amazonaws.com)|52.219.62.95|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 548591089 (523M) [binary/octet-stream]\n",
            "Saving to: ‘cinic-10_image_classification_challenge-dataset.zip’\n",
            "\n",
            "cinic-10_image_clas 100%[===================>] 523.18M  12.2MB/s    in 57s     \n",
            "\n",
            "2021-04-17 07:49:16 (9.21 MB/s) - ‘cinic-10_image_classification_challenge-dataset.zip’ saved [548591089/548591089]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaTApBo3zUVy"
      },
      "source": [
        "# import zipfile\n",
        "# with zipfile.ZipFile('/content/cinic-10_image_classification_challenge-dataset.zip', 'r') as zip_ref:\n",
        "#     zip_ref.extractall('/content/drive/MyDrive/Dockship_Dataset/CINIC-10 Image Classification Challenge')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnOs5Ef0zt8T"
      },
      "source": [
        "#Importing All libararies\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "import random\n",
        "import os\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, Dense\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import EfficientNetB0, VGG16\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "import sys\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjoQO27O1yZt"
      },
      "source": [
        "#Saving the directory of correct images in a dataframe along with label\n",
        "image_id = []\n",
        "object_type = []\n",
        "dir1 = '/content/drive/MyDrive/Dockship_Dataset/CINIC-10 Image Classification Challenge/cinic-10_image_classification_challenge-dataset/train/'\n",
        "for dirname in os.listdir(dir1):\n",
        "    if dirname!='.DS_Store':\n",
        "        for filename in os.listdir(dir1+dirname):\n",
        "              image_id.append(dir1+dirname+'/'+filename)\n",
        "              object_type.append(dirname)\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-iGnL7v14YX",
        "outputId": "96faa779-7032-45e7-8a1f-b4f7c694a99d"
      },
      "source": [
        "#total no of images\n",
        "len(image_id)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "90000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoUgVN2N16rj"
      },
      "source": [
        "df = pd.DataFrame(list(zip(image_id, object_type)),columns = ['ImageID','Type'])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aul9Cw9P3oLf"
      },
      "source": [
        "# Shuffling the data frame\n",
        "df = df.sample(frac=1).reset_index(drop=True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Do9OIJkv3oxj",
        "outputId": "3a04716d-b7f1-4a97-dc10-504fa4cc739e"
      },
      "source": [
        "inp = df['ImageID']\n",
        "out = df['Type']\n",
        "inp, out"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0        /content/drive/MyDrive/Dockship_Dataset/CINIC-...\n",
              " 1        /content/drive/MyDrive/Dockship_Dataset/CINIC-...\n",
              " 2        /content/drive/MyDrive/Dockship_Dataset/CINIC-...\n",
              " 3        /content/drive/MyDrive/Dockship_Dataset/CINIC-...\n",
              " 4        /content/drive/MyDrive/Dockship_Dataset/CINIC-...\n",
              "                                ...                        \n",
              " 89995    /content/drive/MyDrive/Dockship_Dataset/CINIC-...\n",
              " 89996    /content/drive/MyDrive/Dockship_Dataset/CINIC-...\n",
              " 89997    /content/drive/MyDrive/Dockship_Dataset/CINIC-...\n",
              " 89998    /content/drive/MyDrive/Dockship_Dataset/CINIC-...\n",
              " 89999    /content/drive/MyDrive/Dockship_Dataset/CINIC-...\n",
              " Name: ImageID, Length: 90000, dtype: object, 0               cat\n",
              " 1               cat\n",
              " 2        automobile\n",
              " 3               dog\n",
              " 4          airplane\n",
              "             ...    \n",
              " 89995         truck\n",
              " 89996          ship\n",
              " 89997           dog\n",
              " 89998           dog\n",
              " 89999          deer\n",
              " Name: Type, Length: 90000, dtype: object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPSMDuMN3q-C"
      },
      "source": [
        "#splitting the data set   \n",
        "train_input, test_input, train_output, test_output = train_test_split(inp, out, random_state = 42,test_size = 0.2,stratify = out)      "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHtCE39q3s8D"
      },
      "source": [
        "IMG_SIZE = 200\n",
        "size = (IMG_SIZE,IMG_SIZE)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3jfAHT63u45"
      },
      "source": [
        "# Creating an object for imagedatagenerator for generating data in bacthes and augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "                    rotation_range = 40,\n",
        "                    width_shift_range = 0.2,\n",
        "                    height_shift_range = 0.2,\n",
        "                    shear_range = 0.2,\n",
        "                    zoom_range = 0.2,\n",
        "                    horizontal_flip = True,\n",
        "                    vertical_flip = True,\n",
        "                    fill_mode = 'nearest'\n",
        ")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6rydIKf3wYo"
      },
      "source": [
        "train = pd.concat([train_input,train_output],axis=1)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTZKVUYY3yqj",
        "outputId": "d32e4634-9677-4f8e-f690-55ad2ad2d783"
      },
      "source": [
        "# Visualising the class soplit\n",
        "from collections import Counter \n",
        "Counter(object_type)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'airplane': 9000,\n",
              "         'automobile': 9000,\n",
              "         'bird': 9000,\n",
              "         'cat': 9000,\n",
              "         'deer': 9000,\n",
              "         'dog': 9000,\n",
              "         'frog': 9000,\n",
              "         'horse': 9000,\n",
              "         'ship': 9000,\n",
              "         'truck': 9000})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bZh5d0v30g_",
        "outputId": "af775d89-015c-4267-aa3a-c4953e196195"
      },
      "source": [
        "train_generator = datagen.flow_from_dataframe(\n",
        "                    train,\n",
        "                    x_col = \"ImageID\",\n",
        "                    y_col = \"Type\",\n",
        "                    target_size = size,\n",
        "                    class_mode = \"sparse\",\n",
        "                    batch_size = 64,\n",
        "                    shuffle = True,\n",
        "                    seed = 42,\n",
        "                    interpolation = \"nearest\"\n",
        ")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 72000 validated image filenames belonging to 10 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjQei8ZJ32cI"
      },
      "source": [
        "test = pd.concat([test_input,test_output],axis=1)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsKTndrt32ya",
        "outputId": "9f66ea97-84d8-4f6a-9cae-648f7ef5591d"
      },
      "source": [
        "valid_generator = datagen.flow_from_dataframe(\n",
        "                    test,\n",
        "                    x_col = \"ImageID\",\n",
        "                    y_col = \"Type\",\n",
        "                    target_size = size,\n",
        "                    class_mode = \"sparse\",\n",
        "                    batch_size = 64,\n",
        "                    shuffle = False,\n",
        "                    seed = 42,\n",
        "                    interpolation = \"nearest\"\n",
        ")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 18000 validated image filenames belonging to 10 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mve6V9bY320e"
      },
      "source": [
        "NUM_CLASSES = 10"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aHGIfj2322z"
      },
      "source": [
        "def create_model():\n",
        "    model = models.Sequential()\n",
        "    model.add(EfficientNetB0(input_shape = (IMG_SIZE, IMG_SIZE, 3), include_top = False, weights = 'imagenet'))\n",
        "    model.add(layers.GlobalAveragePooling2D())\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(512, activation = 'relu'))\n",
        "    model.add(layers.Dropout(0.25))\n",
        "    model.add(layers.Dense(NUM_CLASSES, activation = 'softmax'))\n",
        "    return model"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d20kY6Jg3244",
        "outputId": "3c4c5a7f-b509-4fb3-ce06-70d28cf0a9cf"
      },
      "source": [
        "model = create_model()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "16711680/16705208 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmJWi2F0326_"
      },
      "source": [
        "model.compile(loss = 'sparse_categorical_crossentropy',\n",
        "             optimizer = Adam(learning_rate = 0.0001),\n",
        "             metrics = ['accuracy'])"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rPn2f-9329U"
      },
      "source": [
        "# Stop training when the validation loss metric has stopped decreasing for 5 epochs.\n",
        "early_stopping = EarlyStopping(monitor = 'val_loss',\n",
        "                               patience = 5,\n",
        "                               mode = 'min',\n",
        "                               restore_best_weights = True)\n",
        "\n",
        "# Save the model with the minimum validation loss\n",
        "checkpoint = ModelCheckpoint('/content/drive/MyDrive/Dockship_Dataset/Models/CINIC_10_best_model.hdf', \n",
        "                             monitor = 'val_loss',\n",
        "                             verbose = 1,\n",
        "                             mode = 'min', \n",
        "                             save_best_only = True)\n",
        "# reduce learning rate\n",
        "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss',\n",
        "                              factor = 0.2,\n",
        "                              patience = 3,\n",
        "                              min_lr = 0.001,\n",
        "                              mode = 'min',\n",
        "                              verbose = 1)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWmJghZp32_o"
      },
      "source": [
        "#Trying with 30 epochs\n",
        "history = model.fit(train_generator,\n",
        "                    validation_data = valid_generator,\n",
        "                    epochs = 30,\n",
        "                    callbacks = [early_stopping, checkpoint, reduce_lr]\n",
        "                    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bdQOsNQ4N8Z"
      },
      "source": [
        "saved_model = tf.keras.models.load_model('/content/drive/MyDrive/Dockship_Dataset/Models/CINIC_10_best_model.hdf')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t29yJM2w4N_U"
      },
      "source": [
        "#function which will return the probabilities of respective classes and the type of object\n",
        "def predict(path):\n",
        "  img = image.load_img(path=path ,target_size=(200, 200,3))\n",
        "  img_array = image.img_to_array(img)\n",
        "  img_batch = np.expand_dims(img_array, axis=0)\n",
        "  prediction = saved_model.predict(img_batch)\n",
        "  result= np.argmax(prediction,axis=1)\n",
        "  class_indices = list(valid_generator.class_indices.keys())\n",
        "  return (class_indices[result[0]],max(prediction[0])*100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DN5CURK4OBU"
      },
      "source": [
        "predict('/content/drive/MyDrive/Dockship_Dataset/Garbage_Classification_AI_Challenge/garbage_classification_ai_challenge-dataset/TEST/001.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9jgEYZc4OD2"
      },
      "source": [
        "result = []\n",
        "for add in test_input:\n",
        "  result.append(predict(add)[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eQ-QTIl4OGD"
      },
      "source": [
        "result[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HBWCjCZ49zo"
      },
      "source": [
        "list(test_output[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFKrni6V4917"
      },
      "source": [
        "confusion_matrix(list(test_output),result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaKxA90e4938"
      },
      "source": [
        "history.history.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "833Fq2K7495-"
      },
      "source": [
        "plt.plot(range(1,9),history.history['val_accuracy'],color='red',label='val_accuracy')\n",
        "plt.plot(range(1, 9),history.history['accuracy'],color='blue',label='train_accuracy')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUmlwRp84OIT"
      },
      "source": [
        "plt.plot(range(1,9),history.history['loss'],color='blue',label='loss')\n",
        "plt.plot(range(1,9),history.history['val_loss'],color='red',label='val_loss')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EANNltJr33Bc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jl03IwmM5LgC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwVaPGew5Lii"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOKZ8E3G5Lk3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjpkaRZx5LnJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ou74ytee5LqA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sazqjcsJ5Lr4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jMaYv1m5Lt2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}